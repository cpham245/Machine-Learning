---
title: "Homework 4"
author: "PSTAT 131/231"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Tree-Based Models

For this assignment, we will be working with the file `"pokemon.csv"`, found in `/data`. The file is from Kaggle: <https://www.kaggle.com/abcsds/pokemon>.

The [Pokémon](https://www.pokemon.com/us/) franchise encompasses video games, TV shows, movies, books, and a card game. This data set was drawn from the video game series and contains statistics about 721 Pokémon, or "pocket monsters." In Pokémon games, the user plays as a trainer who collects, trades, and battles Pokémon to (a) collect all the Pokémon and (b) become the champion Pokémon trainer.

Each Pokémon has a [primary type](https://bulbapedia.bulbagarden.net/wiki/Type) (some even have secondary types). Based on their type, a Pokémon is strong against some types, and vulnerable to others. (Think rock, paper, scissors.) A Fire-type Pokémon, for example, is vulnerable to Water-type Pokémon, but strong against Grass-type.

![Fig 1. Houndoom, a Dark/Fire-type canine Pokémon from Generation II.](images/houndoom.jpg){width="200"}

The goal of this assignment is to build a statistical learning model that can predict the **primary type** of a Pokémon based on its generation, legendary status, and six battle statistics.

**Note: Fitting ensemble tree-based models can take a little while to run. Consider running your models outside of the .Rmd, storing the results, and loading them in your .Rmd to minimize time to knit.**

### Exercise 1: Preprocessing the data

Read in the data and set things up:

a.  Install and load the `janitor` package. Use its `clean_names()` function on the Pokémon data.

```{r}
library(tidyverse)
library(tidymodels)
library(janitor)
library(corrplot)
library(rpart.plot)
library(ranger) 
library(vip)
library(xgboost)
pokemon <- read_csv("data/Pokemon.csv")
```

b.  Filter out the rarer Pokémon types: Using the entire data set, create a bar chart of the outcome variable, `type_1`.
```{r}
pokemon <- pokemon %>%
  clean_names() %>% 
  filter(type_1 %in% c('Bug', 'Fire', 'Grass', 'Normal', 'Water', 'Psychic'))

pokemon %>%
  ggplot(aes(x = type_1, fill = type_1)) +
  geom_bar(color = "black") + 
  ggtitle("Distribution of Type 1 Pokemons") + 
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Type 1 Pokemons")


```

c.  Convert `type_1`, `legendary`, and `generation` to factors.

```{r}
pokemon <- pokemon %>% 
  mutate(type_1 = factor(type_1), 
         legendary = factor(legendary),
         generation = factor(generation))

```

**How many classes of the outcome are there? Are there any Pokémon types with very few Pokémon? If so, which ones?**

From our results above, we see there is total of 6 classes of the outcome. We notice that Fire and Psychic have lower counts compared to the rest.

For this assignment, we'll handle the rarer classes by grouping them, or "lumping them," together into an 'other' category. [Using the `forcats` package](https://forcats.tidyverse.org/), determine how to do this, and **lump all the other levels together except for the top 6 most frequent** (which are Bug, Fire, Grass, Normal, Water, and Psychic).

d.  Do an initial split of the data; you can choose the percentage for splitting. Stratify on the outcome variable.

```{r}
set.seed(1178)
pokemon_split <- initial_split(pokemon, prop = 0.7, strata = type_1)

#Training data
pokemon_train <- training(pokemon_split)

#Testing data
pokemon_test <- testing(pokemon_split)
```

e.  Fold the training set using *v*-fold cross-validation, with `v = 5`. Stratify on the outcome variable.

```{r}
pokemon_folds <- vfold_cv(pokemon_train, v = 5, strata = type_1)
```

f.  Set up a recipe to predict `type_1` with `legendary`, `generation`, `sp_atk`, `attack`, `speed`, `defense`, `hp`, and `sp_def`:

-   Dummy-code `legendary` and `generation`;
-   Center and scale all predictors.

```{r}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + 
                         sp_atk + attack + speed + defense + 
                         hp + sp_def, data = pokemon_train) %>% 
  step_dummy(legendary, generation) %>%  # dummy-encoding
  step_normalize(all_predictors()) # scales predictors


```

### Exercise 2

Create a correlation matrix of the training set, using the `corrplot` package.

```{r}
pokemon %>%
  select_if(is.numeric) %>%
  select(-number) %>%
  cor() %>%
  corrplot(type = "lower", diag = FALSE, addCoef.col = "black")
```

*Note: You can choose how to handle the continuous variables for this plot; justify your decision(s).*

I excluded generation and legendary from the correlation matrix because they are not continuous numeric variables: generation is a discrete variable representing distinct game releases, and legendary is a binary indicator. Including these variables could produce misleading correlations, as they do not have a natural numerical scale and could introduce artificial relationships. Excluding them ensures the analysis focuses on true linear relationships between core numeric attributes like hp, attack, and defense, leading to more accurate and interpretable insights.

**What relationships, if any, do you notice? Do these relationships make sense to you?**

Based on the correlation matrix, we see a strong positive correlation between `total` and `attack` (0.75) `sp_atk` (0.75), and `sp_def` (0.74). Therse are the highest correlations in the matrix which makes sense since the `total` stat is the sum of all individual stats; high values in these stats contribute to a higher total score. We also see a moderate positive correlation between `sp_atk` and `attack` (0.44) which makes sense since Pokemon designed to be strong attackers tend to have balanced offensive attacks. Another moderate positive correlation is between `defense` and `sp_def` (0.55), indicating many Pokemon with good physical defenses also have good special defenses. As expected, we notice `speed` has lower correlations with the rest of the stats, especially `hp` (0.13) and `defense`(0.1). This is expected since speed tends to be more of an individual stats, not tied to hp, attack or defense values.

### Exercise 3

First, set up a decision tree model and workflow. Tune the `cost_complexity` hyperparameter. Use the same levels we used in the Lab -- that is, `range = c(-3, -1)`. Specify that the metric we want to optimize is `roc_auc`.

```{r}
# Set up decision tree model 
decision_tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification") %>%
  set_args(cost_complexity = tune())

# Set up workflow
decision_tree_wf <- workflow() %>% 
  add_model(decision_tree_spec) %>% 
  add_recipe(pokemon_recipe)

# Define Grid for Hyperparameter Tuning
hyperparam_grid <- grid_regular(cost_complexity(range = c(-3,-1)),
                        levels = 10)

```

Perform Cross-Validation with tuning

```{r, eval=FALSE}
tune_class <- tune_grid(
  decision_tree_wf, 
  resamples = pokemon_folds, 
  grid = hyperparam_grid,
  metrics = metric_set(roc_auc)
)

save(tune_class, file = "tune_class.rds")


```

Print an `autoplot()` of the results. What do you observe? Does a single decision tree perform better with a smaller or larger complexity penalty?

```{r}
load("tune_class.rds")
autoplot(tune_class) 

```

From the plot, a single decision tree performs better with a smaller complexity penalty. At values close to 0.020, the ROC AUC is the highest (around 0.65). We see that the ROC AUC decreases as the cost-complexity parameter increases, indicating the model's performance is better with a smaller complexity penalty and worsens with a larger complexity penalty.

### Exercise 4

What is the `roc_auc` of your best-performing pruned decision tree on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*

```{r}
tune_class %>%
  collect_metrics() %>%
  arrange(desc(mean)) 
```

The best-performing pruned decision tree on the folds has a complexity parameter value of about 0.02 and achieves the area under the ROC curve of 0.66.

### Exercise 5

Using `rpart.plot`, fit and visualize your best-performing pruned decision tree with the *training* set.

```{r}
best_pruned_tree <- select_best(tune_class, metric = "roc_auc")
final_df <- finalize_workflow(decision_tree_wf, best_pruned_tree)
final_df_model <- fit(final_df, pokemon_train)

final_df_model %>%
  extract_fit_engine() %>%
  rpart.plot()
```

### Exercise 6

Now set up a random forest model and workflow. Use the `ranger` engine and set `importance = "impurity"`. Tune `mtry`, `trees`, and `min_n`. Using the documentation for `rand_forest()`, explain in your own words what each of these hyperparameters represent.

```{r}
rf_spec <- rand_forest(mtry = tune(),
                       trees = tune(),
                       min_n = tune()) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(pokemon_recipe)
```

For rand_forest(), `mtry` represents the number of predictors (features) that are randomly selected at each split when building individual tree models. `trees` represent the total number of decision trees in the random forest model. `min_n` defines the minimum number of observations required in a node for it to be split further. 

Create a regular grid with 8 levels each. You can choose plausible ranges for each hyperparameter. Note that `mtry` should not be smaller than 1 or larger than 8. **Explain why not. What type of model would `mtry = 8` represent?**

```{r}
reg_grid <- grid_regular(mtry(range= c(1,8)),
                         min_n(range = c(6, 20)),
                         trees(range = c(200, 800)),
                         levels = 8)
```

`mtry` should not be smaller than 1 since it would be mean sampling a negative number of features or zero which does not make sense. `mtry` cannot also be larger than 8, since that would mean we are sampling more predictors that are available. If `mtry = 8`, it would be a bagged decision tree model since all features are considered at each split.

### Exercise 7

Specify `roc_auc` as a metric. Tune the model and print an `autoplot()` of the results. What do you observe? What values of the hyperparameters seem to yield the best performance?
```{r, eval = FALSE}
rf_class <- tune_grid(
  rf_wf, 
  resamples = pokemon_folds, 
  grid = reg_grid,
  metrics = metric_set(roc_auc)
)

save(rf_class, file = "rf_class.rds")
```

```{r}
load("rf_class.rds")
autoplot(rf_class)
```

From our 8 plots, the ROC AUC score seems to peak when `mtry = 2 or 3`, suggesting a small subset of predictors at each split results in better performance, reducing overfitting. In addition, the best `min_n` values seem to be 6-12, as the variability in performance decreases across different tree counts. We also see that at around 500-600 trees, our model performs the best.
### Exercise 8

What is the `roc_auc` of your best-performing random forest model on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*
```{r}
best_rf <- rf_class %>%
  collect_metrics() %>% 
  arrange(desc(mean)) 

best_rf
```

The best-performing random forest model on the folds has a `mtry` value of 4, `trees` amount of 457, and `min_n` of 12. The model achieves the area under the ROC curve of 0.73.

### Exercise 9

Create a variable importance plot, using `vip()`, with your best-performing random forest model fit on the *training* set.

Which variables were most useful? Which were least useful? Are these results what you expected, or not?

```{r}
best_rf <- select_best(rf_class)
best_forest <- finalize_workflow(rf_wf, best_rf)
best_forest_final <- fit(best_forest, pokemon_train)

best_forest_final %>%
  extract_fit_parsnip() %>%
  vip()
```

This plot tells us that the three most useful predictors are `sp_atk`,`speed`, and `attack`. This was expected since offensive stats like `sp_atk` and `attack` and battle-skills like `speed` are naturally important for predicting a Pokemon's type. The least useful predictors are `generation` types and `legendary` status as they are descriptors of the pokemon rather than directly indicative of a Pokemon's type. `generation` indicates when a Pokemon was introduced, but doesn't determine its type. 
`legendary` status is loosely related to type, as many pokemon can be legendary.

### Exercise 10

Finally, set up a boosted tree model and workflow. Use the `xgboost` engine. Tune `trees`. Create a regular grid with 10 levels; let `trees` range from 10 to 2000. Specify `roc_auc` and again print an `autoplot()` of the results.

```{r}
bt_class_spec <- boost_tree(mtry = tune(), 
                           trees = tune(), 
                           learn_rate = tune()) %>%
  set_engine("xgboost") %>% 
  set_mode("classification")

bt_class_wf <- workflow() %>% 
  add_model(bt_class_spec) %>% 
  add_recipe(pokemon_recipe)

# Create grid
bt_grid <- grid_regular(mtry(range = c(1, 8)), 
                        trees(range = c(10, 2000)),
                        learn_rate(range = c(-10, -1)),
                        levels = 10)

#Tune grid
tune_bt_class <- tune_grid(
  bt_class_wf,
  resamples = pokemon_folds,
  grid = bt_grid,
  metrics = metric_set(roc_auc))

save(tune_bt_class, file = "tune_bt_class.rda")

```
```{r}
load("tune_bt_class.rda")
autoplot(tune_bt_class)

```
What do you observe?

From our graphs, we see that the performance improves as the number of tree increases, with the ROC AUC scores increasing initially and then stabilizing around 500-1000 trees. We also notice that higher learning rates (1e-1, 1e-2, etc.) achieve much better ROC AUC scores while small learning rates (1e-8, 1e-9, etc.) perform poorly as seen by the colors displayed in the graphs. Our otimal hyperparameters seems to be around 500-100 trees and a learning rate of 1e-1 or 1e-2.

What is the `roc_auc` of your best-performing boosted tree model on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*
```{r}
tune_bt_class  %>%
  collect_metrics() %>% 
  arrange(desc(mean))
```

From our table, the best performing model boosted tree model has a `mtry = 4`, `trees = 894`, `learn_rate = 1e-02`, and achieves the area under the ROC curve of 0.72.

### Exercise 11

Display a table of the three ROC AUC values for your best-performing pruned tree, random forest, and boosted tree models. Which performed best on the folds? Select the best of the three and use `select_best()`, `finalize_workflow()`, and `fit()` to fit it to the *testing* set.

| Model         | ROC AUC Values |
|---------------|----------------|
| Pruned tree   |     0.662      |
| Random forest |     0.731      |
| Boosted tree  |     0.724      |

From the table our random forest model performs the best on the folds.

Print the AUC value of your best-performing model on the testing set. 
```{r}
best_rf_model <- select_best(rf_class)
rf_finalwf <- finalize_workflow(rf_wf, best_rf_model)
final_rf_model <- fit(rf_finalwf, pokemon_train)

final_rf_test <- augment(final_rf_model, pokemon_test) %>%
  select(type_1, starts_with(".pred"))

roc_auc(final_rf_test, truth = type_1, .pred_Bug:.pred_Water)
```
Print the ROC curves. 
```{r} 
#ROC Curve
roc_curve(final_rf_test, truth = type_1, .pred_Bug:.pred_Water) %>%
  autoplot()

```

Finally, create and visualize a confusion matrix heat map.
```{r}
#Confusion matrix heat map
conf_mat(final_rf_test, truth = type_1, 
         .pred_class) %>% 
  autoplot(type = "heatmap")

```

Which classes was your model most accurate at predicting? Which was it worst at?

From our confusion matrix heatmap, our model is most accurate at predicting the Normal type for Pokemon, achieving 13 true value. Our model is the worst at predicting the Grass type, with a true prediction of 2.

## For 231 Students

### Exercise 12

Using the `abalone.txt` data from previous assignments, fit and tune a random forest model to predict `age`. Use stratified cross-validation and select ranges for `mtry`, `min_n`, and `trees`. Present your results. What was the model's RMSE on your testing set?
